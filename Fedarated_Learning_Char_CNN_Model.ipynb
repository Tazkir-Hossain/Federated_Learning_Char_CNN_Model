{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tazkir-Hossain/Federated_Learning_Char_CNN_Model/blob/main/Fedarated_Learning_Char_CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-qiINBQSK2g"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import string\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwEPNDWySTKm"
      },
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "X_raw = dataset.iloc[:, 1].astype(str).values  # Raw URLs\n",
        "y_raw = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_CHARACTERS = string.ascii_letters + string.digits + string.punctuation\n",
        "CHAR2IDX = {char: idx for idx, char in enumerate(ALL_CHARACTERS)}\n",
        "NUM_CHARACTERS = len(ALL_CHARACTERS)\n",
        "MAX_LENGTH = 200  # You can adjust this\n",
        "\n",
        "def one_hot_encode_url(url, max_length):\n",
        "    encoded = np.zeros((max_length, NUM_CHARACTERS), dtype=np.float32)\n",
        "    for i, char in enumerate(url[:max_length]):\n",
        "        if char in CHAR2IDX:\n",
        "            encoded[i, CHAR2IDX[char]] = 1.0\n",
        "    return encoded\n",
        "\n",
        "# Encode URLs\n",
        "X_encoded = np.array([one_hot_encode_url(url, MAX_LENGTH) for url in X_raw])\n",
        "\n",
        "# Convert to tensors\n",
        "X_tensor = torch.tensor(X_encoded)\n",
        "y_tensor = torch.tensor(y).unsqueeze(1)"
      ],
      "metadata": {
        "id": "m7tPfaI4UzlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target: Binary 'Adult' = 1, Others = 0\n",
        "y = np.array([1 if label.lower() == \"adult\" else 0 for label in y_raw], dtype=np.float32)\n",
        "y_tensor = torch.tensor(y).unsqueeze(1)\n"
      ],
      "metadata": {
        "id": "bKFUIjRiSyFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset and DataLoader"
      ],
      "metadata": {
        "id": "8u1okR-qWa6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "E53MuGeRWmfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# Define dataset again (if not already)\n",
        "full_dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "# Calculate lengths\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "val_size = int(0.15 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "# Split dataset\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "PnE9v-w0VBAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building\n"
      ],
      "metadata": {
        "id": "VVnithWq-AvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Json Configaration\n"
      ],
      "metadata": {
        "id": "NXyasGKc-MMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "    \"alphabet\": {\n",
        "        \"en\": {\n",
        "            \"lower\": {\n",
        "                \"alphabet\": \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\",\n",
        "                \"number_of_characters\": 69\n",
        "            },\n",
        "            \"both\": {\n",
        "                \"alphabet\": \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\",\n",
        "                \"number_of_characters\": 95\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"model_parameters\": {\n",
        "        \"small\": {\n",
        "            \"conv\": [\n",
        "                [256, 7, 3],\n",
        "                [256, 7, 3],\n",
        "                [256, 3, -1],\n",
        "                [256, 3, -1],\n",
        "                [256, 3, -1],\n",
        "                [256, 3, 3]\n",
        "            ],\n",
        "            \"fc\": [1024, 1024]\n",
        "        }\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"text_column\": \"url\",\n",
        "        \"label_column\": \"category\",\n",
        "        \"max_length\": 200,\n",
        "        \"num_of_classes\": 2,\n",
        "        \"encoding\": None,\n",
        "        \"chunksize\": 50000,\n",
        "        \"max_rows\": 100000,\n",
        "        \"preprocessing_steps\": [\n",
        "            \"lower\"\n",
        "        ]\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"batch_size\": 128,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"epochs\": 10,\n",
        "        \"optimizer\": \"sgd\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save the file\n",
        "with open(\"config.json\", \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n"
      ],
      "metadata": {
        "id": "MRrOx8Cm-EKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Char-CNN Model Building Code"
      ],
      "metadata": {
        "id": "kv5ZByJK-Vbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CharacterLevelCNN(nn.Module):\n",
        "    def __init__(self, args, number_of_classes):\n",
        "        super(CharacterLevelCNN, self).__init__()\n",
        "\n",
        "        # define conv layers\n",
        "\n",
        "        self.dropout_input = nn.Dropout2d(args.dropout_input)\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                args.number_of_characters + len(args.extra_characters),\n",
        "                256,\n",
        "                kernel_size=7,\n",
        "                padding=0,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(3),\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(256, 256, kernel_size=7, padding=0), nn.ReLU(), nn.MaxPool1d(3)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=0), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=0), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=0), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=0), nn.ReLU(), nn.MaxPool1d(3)\n",
        "        )\n",
        "\n",
        "        # compute the  output shape after forwarding an input to the conv layers\n",
        "\n",
        "        input_shape = (\n",
        "            128,\n",
        "            args.max_length,\n",
        "            args.number_of_characters + len(args.extra_characters),\n",
        "        )\n",
        "        self.output_dimension = self._get_conv_output(input_shape)\n",
        "\n",
        "        # define linear layers\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(self.output_dimension, 1024), nn.ReLU(), nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Sequential(nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(0.5))\n",
        "\n",
        "        self.fc3 = nn.Linear(1024, number_of_classes)\n",
        "\n",
        "        # initialize weights\n",
        "\n",
        "        self._create_weights()\n",
        "\n",
        "    # utility private functions\n",
        "\n",
        "    def _create_weights(self, mean=0.0, std=0.05):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "                module.weight.data.normal_(mean, std)\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        x = torch.rand(shape)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output_dimension = x.size(1)\n",
        "        return output_dimension\n",
        "\n",
        "    # forward\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout_input(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_AP3raih-cRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}